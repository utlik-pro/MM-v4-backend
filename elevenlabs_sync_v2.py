#!/usr/bin/env python3
"""
ElevenLabs Sync v2 - –ü—Ä–∞–≤–∏–ª—å–Ω–∞—è —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è —Å –∞–≥–µ–Ω—Ç–æ–º

–ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è:
1. –ü—Ä–∞–≤–∏–ª—å–Ω—ã–π –ø—É—Ç—å: conversation_config.agent.prompt.knowledge_base
2. –ó–∞–≥—Ä—É–∂–∞–µ—Ç —Ç–æ–ª—å–∫–æ –∏–∑–º–µ–Ω—ë–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã (–ø–æ —Ö–µ—à—É)
3. –ó–∞–º–µ–Ω—è–µ—Ç —Å—Ç–∞—Ä—ã–µ –≤–µ—Ä—Å–∏–∏ –Ω–∞ –Ω–æ–≤—ã–µ (–Ω–µ –¥–æ–±–∞–≤–ª—è–µ—Ç)
4. –£–¥–∞–ª—è–µ—Ç —Å—Ç–∞—Ä—ã–µ –≤–µ—Ä—Å–∏–∏ –∏–∑ KB –ø–æ—Å–ª–µ –æ—Ç–≤—è–∑–∫–∏ –æ—Ç –∞–≥–µ–Ω—Ç–∞
"""

import os
import sys
import json
import time
import hashlib
import argparse
import requests
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Optional

# –ó–∞–≥—Ä—É–∂–∞–µ–º .env –µ—Å–ª–∏ –µ—Å—Ç—å
try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    pass

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
API_KEY = os.environ.get('ELEVENLABS_API_KEY')
AGENT_ID = os.environ.get('ELEVENLABS_AGENT_ID')
BASE_URL = "https://api.elevenlabs.io/v1"

# –ü–æ—Å—Ç–æ—è–Ω–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã (–Ω–µ –æ–±–Ω–æ–≤–ª—è–µ–º)
PERMANENT_DOCS = {
    '–ú–ë–ê', '00-obschie-svedeniya', '01-obrazovatelnaya-infrastruktura',
    '02-parkinki-i-sport', '03-finansovye-uslugi', '03-empathy-enhancer',
    '05-sroki-sdachi-domov'
}

STATE_FILE = Path('./quarters_state.json')


def log(msg: str):
    """–í—ã–≤–æ–¥ —Å timestamp"""
    timestamp = datetime.now().strftime('%H:%M:%S')
    print(f"[{timestamp}] {msg}", flush=True)


def get_headers() -> dict:
    return {"xi-api-key": API_KEY}


def load_state() -> dict:
    """–ó–∞–≥—Ä—É–∑–∏—Ç—å —Å–æ—Å—Ç–æ—è–Ω–∏–µ"""
    if STATE_FILE.exists():
        with open(STATE_FILE, 'r', encoding='utf-8') as f:
            return json.load(f)
    return {"quarters": {}, "permanent_docs": {}}


def save_state(state: dict):
    """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Å–æ—Å—Ç–æ—è–Ω–∏–µ"""
    state["last_update"] = datetime.now().isoformat()
    with open(STATE_FILE, 'w', encoding='utf-8') as f:
        json.dump(state, f, ensure_ascii=False, indent=2)


def calculate_hash(file_path: str) -> str:
    """MD5 —Ö–µ—à —Ñ–∞–π–ª–∞"""
    with open(file_path, 'rb') as f:
        return hashlib.md5(f.read()).hexdigest()


def get_agent_kb() -> List[Dict]:
    """–ü–æ–ª—É—á–∏—Ç—å knowledge_base –∞–≥–µ–Ω—Ç–∞ (–ü–†–ê–í–ò–õ–¨–ù–´–ô –ü–£–¢–¨!)"""
    url = f"{BASE_URL}/convai/agents/{AGENT_ID}"
    resp = requests.get(url, headers=get_headers(), timeout=60)
    
    if resp.status_code != 200:
        log(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∞–≥–µ–Ω—Ç–∞: {resp.status_code}")
        return []
    
    data = resp.json()
    # –ü–†–ê–í–ò–õ–¨–ù–´–ô –ü–£–¢–¨!
    kb = data.get('conversation_config', {}).get('agent', {}).get('prompt', {}).get('knowledge_base', [])
    return kb


def upload_document(file_path: str, name: str) -> Optional[str]:
    """–ó–∞–≥—Ä—É–∑–∏—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç –≤ KB"""
    url = f"{BASE_URL}/convai/knowledge-base"
    
    with open(file_path, 'rb') as f:
        files = {'file': (f"{name}.md", f, 'text/markdown')}
        resp = requests.post(url, headers=get_headers(), files=files, timeout=120)
    
    if resp.status_code in [200, 201]:
        doc_id = resp.json().get('id')
        return doc_id
    else:
        log(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ {name}: {resp.status_code}")
        return None


def wait_for_indexing(doc_id: str, max_wait: int = 5) -> bool:
    """–ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –ø–∞—É–∑–∞ –ø–æ—Å–ª–µ –∑–∞–≥—Ä—É–∑–∫–∏
    
    ElevenLabs –∏–Ω–¥–µ–∫—Å–∏—Ä—É–µ—Ç –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ - –¥–æ–∫—É–º–µ–Ω—Ç—ã —Ä–∞–±–æ—Ç–∞—é—Ç —Å—Ä–∞–∑—É,
    –ø–æ–ª–Ω–∞—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è –¥–ª—è —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏—è.
    """
    # –ü—Ä–æ—Å—Ç–æ –Ω–µ–±–æ–ª—å—à–∞—è –ø–∞—É–∑–∞ —á—Ç–æ–±—ã API —É—Å–ø–µ–ª –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å
    time.sleep(1)
    return True


def update_agent_kb(new_kb: List[Dict]) -> bool:
    """–û–±–Ω–æ–≤–∏—Ç—å KB –∞–≥–µ–Ω—Ç–∞ (–ü–†–ê–í–ò–õ–¨–ù–´–ô –ü–£–¢–¨!)"""
    url = f"{BASE_URL}/convai/agents/{AGENT_ID}"
    
    update_data = {
        "conversation_config": {
            "agent": {
                "prompt": {
                    "knowledge_base": new_kb
                }
            }
        }
    }
    
    log(f"   üì§ PATCH –∑–∞–ø—Ä–æ—Å ({len(new_kb)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤)...")
    
    # Retry —Å —É–≤–µ–ª–∏—á–µ–Ω–Ω—ã–º —Ç–∞–π–º–∞—É—Ç–æ–º
    for attempt in range(3):
        try:
            resp = requests.patch(
                url,
                headers={**get_headers(), "Content-Type": "application/json"},
                json=update_data,
                timeout=(30, 600)  # 30s connect, 10min read (–∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è –º–æ–∂–µ—Ç –±—ã—Ç—å –¥–æ–ª–≥–æ–π)
            )
            
            if resp.status_code == 200:
                log(f"   ‚úÖ –ê–≥–µ–Ω—Ç –æ–±–Ω–æ–≤–ª—ë–Ω —É—Å–ø–µ—à–Ω–æ")
                return True
            else:
                log(f"   ‚ùå –û—à–∏–±–∫–∞: {resp.status_code} - {resp.text[:200]}")
                return False
                
        except requests.exceptions.Timeout:
            log(f"   ‚ö†Ô∏è  –ü–æ–ø—ã—Ç–∫–∞ {attempt + 1}/3: —Ç–∞–π–º–∞—É—Ç")
            if attempt < 2:
                time.sleep(5)
        except Exception as e:
            log(f"   ‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞: {e}")
            return False
    
    log("   ‚ùå –í—Å–µ –ø–æ–ø—ã—Ç–∫–∏ –∏—Å—á–µ—Ä–ø–∞–Ω—ã")
    return False


def delete_document(doc_id: str) -> bool:
    """–£–¥–∞–ª–∏—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç –∏–∑ KB"""
    url = f"{BASE_URL}/convai/knowledge-base/{doc_id}"
    resp = requests.delete(url, headers=get_headers(), timeout=30)
    return resp.status_code in [200, 204]


def init_state_from_agent(agent_docs: dict, quarters_path: Path) -> dict:
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å state –∏–∑ —Ç–µ–∫—É—â–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∞–≥–µ–Ω—Ç–∞"""
    state = {"quarters": {}, "permanent_docs": {}}
    
    for name, doc in agent_docs.items():
        md_file = quarters_path / f"{name}.md"
        content_hash = ""
        if md_file.exists():
            content_hash = calculate_hash(str(md_file))
        
        doc_info = {
            "doc_id": doc.get('id', ''),
            "content_hash": content_hash,
            "last_updated": None
        }
        
        if name in PERMANENT_DOCS:
            state["permanent_docs"][name] = doc_info
        else:
            state["quarters"][name] = doc_info
    
    return state


def sync_quarters(quarters_dir: str = 'quarters', changed_files: List[str] = None, dry_run: bool = False):
    """
    –ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏
    
    Args:
        quarters_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å MD —Ñ–∞–π–ª–∞–º–∏
        changed_files: –°–ø–∏—Å–æ–∫ –∏–∑–º–µ–Ω—ë–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        dry_run: –¢–æ–ª—å–∫–æ –ø–æ–∫–∞–∑–∞—Ç—å —á—Ç–æ –±—É–¥–µ—Ç —Å–¥–µ–ª–∞–Ω–æ
    """
    log("=" * 60)
    log("üöÄ ElevenLabs Sync v2")
    log("=" * 60)
    
    if not API_KEY or not AGENT_ID:
        log("‚ùå –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ ELEVENLABS_API_KEY –∏ ELEVENLABS_AGENT_ID")
        return
    
    quarters_path = Path(quarters_dir)
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º state –∏–ª–∏ —Å–æ–∑–¥–∞—ë–º –Ω–æ–≤—ã–π
    state = load_state()
    
    # –®–∞–≥ 1: –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—É—â–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –∞–≥–µ–Ω—Ç–∞
    log("\nüì• –®–∞–≥ 1: –ü–æ–ª—É—á–µ–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∞–≥–µ–Ω—Ç–∞...")
    agent_kb = get_agent_kb()
    log(f"   –î–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ –∞–≥–µ–Ω—Ç–µ: {len(agent_kb)}")
    
    # –°–æ–∑–¥–∞—ë–º —Å–ª–æ–≤–∞—Ä—å name ‚Üí doc –¥–ª—è –∞–≥–µ–Ω—Ç–∞
    agent_docs = {doc['name']: doc for doc in agent_kb}
    
    # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è state –µ—Å–ª–∏ –ø—É—Å—Ç–æ–π
    if not state.get('quarters'):
        log("‚ö†Ô∏è  State –ø—É—Å—Ç–æ–π, –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∏–∑ –∞–≥–µ–Ω—Ç–∞...")
        state = init_state_from_agent(agent_docs, quarters_path)
        save_state(state)
        log(f"   ‚úÖ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ {len(state['quarters'])} –∫–≤–∞—Ä—Ç–∞–ª–æ–≤")
    
    # –®–∞–≥ 2: –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–∞–∫–∏–µ —Ñ–∞–π–ª—ã –∏–∑–º–µ–Ω–∏–ª–∏—Å—å
    log("\nüîç –®–∞–≥ 2: –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏–∑–º–µ–Ω–µ–Ω–∏–π...")
    
    files_to_update = []
    
    # –ï—Å–ª–∏ –ø–µ—Ä–µ–¥–∞–Ω —Å–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤, –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ
    if changed_files:
        md_files = [quarters_path / f for f in changed_files if f.endswith('.md')]
    else:
        md_files = list(quarters_path.glob('*.md'))
    
    # –ï—Å–ª–∏ —Ñ–∞–π–ª—ã –ø–µ—Ä–µ–¥–∞–Ω—ã —á–µ—Ä–µ–∑ --changed-files, —Å—á–∏—Ç–∞–µ–º –∏—Ö –∏–∑–º–µ–Ω—ë–Ω–Ω—ã–º–∏ (–¥–æ–≤–µ—Ä—è–µ–º sync-with-monitoring)
    force_update = changed_files is not None
    
    for md_file in md_files:
        name = md_file.stem  # –ò–º—è –±–µ–∑ .md
        
        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø–æ—Å—Ç–æ—è–Ω–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã
        if name in PERMANENT_DOCS:
            continue
        
        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Ñ–∞–π–ª—ã –∫–æ—Ç–æ—Ä—ã–µ –ù–ï –ø—Ä–∏–≤—è–∑–∞–Ω—ã –∫ –∞–≥–µ–Ω—Ç—É
        if name not in agent_docs:
            log(f"   ‚è≠Ô∏è  {name} (–Ω–µ –≤ –∞–≥–µ–Ω—Ç–µ, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º)")
            continue
        
        current_hash = calculate_hash(str(md_file))
        saved_hash = state.get('quarters', {}).get(name, {}).get('content_hash', '')
        
        # –ï—Å–ª–∏ –ø–µ—Ä–µ–¥–∞–Ω --changed-files, –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –æ–±–Ω–æ–≤–ª—è–µ–º (–¥–æ–≤–µ—Ä—è–µ–º sync-with-monitoring)
        if force_update or current_hash != saved_hash:
            files_to_update.append({
                'name': name,
                'path': str(md_file),
                'hash': current_hash,
                'old_doc_id': agent_docs.get(name, {}).get('id')
            })
            if force_update:
                log(f"   üîÑ {name} (–ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ)")
            else:
                log(f"   üîÑ {name} (—Ö–µ—à –∏–∑–º–µ–Ω–∏–ª—Å—è)")
        else:
            log(f"   ‚úÖ {name} (–±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π)")
    
    if not files_to_update:
        log("\n‚úÖ –ù–µ—Ç –∏–∑–º–µ–Ω–µ–Ω–∏–π –¥–ª—è —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏")
        return
    
    log(f"\nüìä –ö –æ–±–Ω–æ–≤–ª–µ–Ω–∏—é: {len(files_to_update)} —Ñ–∞–π–ª–æ–≤")
    
    if dry_run:
        log("\n‚ö†Ô∏è  DRY RUN - –∏–∑–º–µ–Ω–µ–Ω–∏—è –Ω–µ –ø—Ä–∏–º–µ–Ω–µ–Ω—ã")
        return
    
    # –®–∞–≥ 3: –ó–∞–≥—Ä—É–∂–∞–µ–º –Ω–æ–≤—ã–µ –≤–µ—Ä—Å–∏–∏
    log("\nüì§ –®–∞–≥ 3: –ó–∞–≥—Ä—É–∑–∫–∞ –Ω–æ–≤—ã—Ö –≤–µ—Ä—Å–∏–π...")
    
    uploaded = []
    for file_info in files_to_update:
        log(f"   üì§ {file_info['name']}...", )
        
        new_doc_id = upload_document(file_info['path'], file_info['name'])
        if new_doc_id:
            file_info['new_doc_id'] = new_doc_id
            uploaded.append(file_info)
            log(f"   ‚úÖ {file_info['name']} ‚Üí {new_doc_id[:20]}...")
        else:
            log(f"   ‚ùå {file_info['name']} - –æ—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏")
    
    if not uploaded:
        log("‚ùå –ù–∏—á–µ–≥–æ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–æ")
        return
    
    # –®–∞–≥ 4: –ü–∞—É–∑–∞ –ø–µ—Ä–µ–¥ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ–º –∞–≥–µ–Ω—Ç–∞
    log("\n‚è≥ –®–∞–≥ 4: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∫ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—é –∞–≥–µ–Ω—Ç–∞...")
    
    # ElevenLabs –∏–Ω–¥–µ–∫—Å–∏—Ä—É–µ—Ç –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ - –¥–æ–∫—É–º–µ–Ω—Ç—ã —Ä–∞–±–æ—Ç–∞—é—Ç —Å—Ä–∞–∑—É
    # –ù–µ–±–æ–ª—å—à–∞—è –ø–∞—É–∑–∞ —á—Ç–æ–±—ã API —É—Å–ø–µ–ª –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –∑–∞–≥—Ä—É–∑–∫–∏
    time.sleep(3)
    
    indexed = uploaded  # –í—Å–µ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–µ –≥–æ—Ç–æ–≤—ã –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é
    log(f"   üìä –î–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è: {len(indexed)}")
    
    # –®–∞–≥ 5: –û–±–Ω–æ–≤–ª—è–µ–º –∞–≥–µ–Ω—Ç–∞ (–∑–∞–º–µ–Ω—è–µ–º —Å—Ç–∞—Ä—ã–µ ID –Ω–∞ –Ω–æ–≤—ã–µ)
    log("\nü§ñ –®–∞–≥ 5: –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∞–≥–µ–Ω—Ç–∞...")
    
    # –°–æ–∑–¥–∞—ë–º –Ω–æ–≤—ã–π KB - –∑–∞–º–µ–Ω—è–µ–º —Å—Ç–∞—Ä—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –Ω–∞ –Ω–æ–≤—ã–µ
    new_agent_kb = []
    old_doc_ids = []  # –î–ª—è —É–¥–∞–ª–µ–Ω–∏—è
    
    for doc in agent_kb:
        name = doc['name']
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –µ—Å—Ç—å –ª–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –¥–ª—è —ç—Ç–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞
        updated = next((f for f in indexed if f['name'] == name), None)
        
        if updated:
            # –ó–∞–º–µ–Ω—è–µ–º –Ω–∞ –Ω–æ–≤—É—é –≤–µ—Ä—Å–∏—é
            new_agent_kb.append({
                'type': doc.get('type', 'text'),
                'name': name,
                'id': updated['new_doc_id'],
                'usage_mode': doc.get('usage_mode', 'auto')
            })
            if updated.get('old_doc_id'):
                old_doc_ids.append(updated['old_doc_id'])
            log(f"   üîÑ {name}: {updated.get('old_doc_id', 'new')[:15]}... ‚Üí {updated['new_doc_id'][:15]}...")
        else:
            # –û—Å—Ç–∞–≤–ª—è–µ–º –∫–∞–∫ –µ—Å—Ç—å
            new_agent_kb.append(doc)
    
    # –û–±–Ω–æ–≤–ª—è–µ–º –∞–≥–µ–Ω—Ç–∞
    if not update_agent_kb(new_agent_kb):
        return
    
    # –®–∞–≥ 6: –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–µ –≤–µ—Ä—Å–∏–∏ –∏–∑ KB
    if old_doc_ids:
        log("\nüóëÔ∏è  –®–∞–≥ 6: –£–¥–∞–ª–µ–Ω–∏–µ —Å—Ç–∞—Ä—ã—Ö –≤–µ—Ä—Å–∏–π...")
        time.sleep(2)  # –î–∞—ë–º –≤—Ä–µ–º—è –Ω–∞ –æ—Ç–≤—è–∑–∫—É
        
        for old_id in old_doc_ids:
            if delete_document(old_id):
                log(f"   ‚úÖ –£–¥–∞–ª—ë–Ω: {old_id[:20]}...")
            else:
                log(f"   ‚ö†Ô∏è  –ù–µ —É–¥–∞–ª—ë–Ω: {old_id[:20]}...")
    
    # –®–∞–≥ 7: –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ
    log("\nüíæ –®–∞–≥ 7: –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è...")
    
    for file_info in indexed:
        state['quarters'][file_info['name']] = {
            'doc_id': file_info['new_doc_id'],
            'content_hash': file_info['hash'],
            'last_updated': datetime.now().isoformat()
        }
    
    save_state(state)
    
    # –ò—Ç–æ–≥–∏
    log("\n" + "=" * 60)
    log("üìä –ò–¢–û–ì–ò:")
    log(f"   üì§ –ó–∞–≥—Ä—É–∂–µ–Ω–æ: {len(uploaded)}")
    log(f"   ‚úÖ –ü—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–æ: {len(indexed)}")
    log(f"   üóëÔ∏è  –£–¥–∞–ª–µ–Ω–æ —Å—Ç–∞—Ä—ã—Ö: {len(old_doc_ids)}")
    log("=" * 60)


def main():
    parser = argparse.ArgumentParser(description='ElevenLabs Sync v2')
    parser.add_argument('--dir', default='quarters', help='–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å MD —Ñ–∞–π–ª–∞–º–∏')
    parser.add_argument('--dry-run', action='store_true', help='–¢–æ–ª—å–∫–æ –ø–æ–∫–∞–∑–∞—Ç—å –∏–∑–º–µ–Ω–µ–Ω–∏—è')
    parser.add_argument('--changed-files', type=str, help='–§–∞–π–ª —Å–æ —Å–ø–∏—Å–∫–æ–º –∏–∑–º–µ–Ω—ë–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤')
    
    args = parser.parse_args()
    
    changed_files = None
    if args.changed_files:
        with open(args.changed_files, 'r') as f:
            changed_files = [line.strip() for line in f if line.strip()]
    
    sync_quarters(
        quarters_dir=args.dir,
        changed_files=changed_files,
        dry_run=args.dry_run
    )


if __name__ == "__main__":
    main()

