#!/usr/bin/env python3
"""
–ü–æ–ª–Ω–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ ElevenLabs: –∑–∞–≥—Ä—É–∑–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤, –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è RAG –∏ –ø—Ä–∏–≤—è–∑–∫–∞ –∫ –∞–≥–µ–Ω—Ç—É
"""

import os
import json
import requests
from dotenv import load_dotenv
import time
from typing import Dict, List

load_dotenv()

api_key = os.getenv('ELEVENLABS_API_KEY')
agent_id = os.getenv('ELEVENLABS_AGENT_ID')
base_url = "https://api.elevenlabs.io/v1"

headers = {
    "xi-api-key": api_key,
    "Content-Type": "application/json"
}

def compute_rag_index(doc_id: str, doc_name: str) -> bool:
    """–í—ã—á–∏—Å–ª—è–µ—Ç RAG –∏–Ω–¥–µ–∫—Å –¥–ª—è –¥–æ–∫—É–º–µ–Ω—Ç–∞"""
    url = f"{base_url}/convai/knowledge-base/{doc_id}/rag-index"
    
    data = {
        "model": "multilingual_e5_large_instruct"  # –ú—É–ª—å—Ç–∏—è–∑—ã—á–Ω–∞—è –º–æ–¥–µ–ª—å –¥–ª—è —Ä—É—Å—Å–∫–æ–≥–æ —Ç–µ–∫—Å—Ç–∞
    }
    
    response = requests.post(url, headers=headers, json=data)
    
    if response.status_code in [200, 201]:
        result = response.json()
        status = result.get('status', 'unknown')
        progress = result.get('progress', 0)
        
        if status == 'indexed':
            print(f"   ‚úÖ {doc_name}: —É–∂–µ –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω")
        elif status == 'created' or status == 'indexing':
            print(f"   üîÑ {doc_name}: –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è –∑–∞–ø—É—â–µ–Ω–∞ ({progress}%)")
        else:
            print(f"   ‚ö†Ô∏è {doc_name}: —Å—Ç–∞—Ç—É—Å {status}")
        
        return True
    else:
        print(f"   ‚ùå {doc_name}: –æ—à–∏–±–∫–∞ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ {response.status_code}")
        return False

def check_rag_status(doc_id: str) -> str:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å—Ç–∞—Ç—É—Å RAG –∏–Ω–¥–µ–∫—Å–∞"""
    url = f"{base_url}/convai/knowledge-base/{doc_id}/rag-index"
    
    response = requests.get(url, headers=headers)
    
    if response.status_code == 200:
        result = response.json()
        
        # API –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ–±—ä–µ–∫—Ç —Å –ø–æ–ª–µ–º indexes
        if isinstance(result, dict) and 'indexes' in result:
            indexes = result.get('indexes', [])
            if indexes and isinstance(indexes, list):
                # –ë–µ—Ä–µ–º —Å—Ç–∞—Ç—É—Å –ø–µ—Ä–≤–æ–≥–æ –∏–Ω–¥–µ–∫—Å–∞
                return indexes[0].get('status', 'unknown')
        # –°—Ç–∞—Ä—ã–π —Ñ–æ—Ä–º–∞—Ç - –º–∞—Å—Å–∏–≤
        elif isinstance(result, list) and result:
            return result[0].get('status', 'unknown')
        # –°—Ç–∞—Ä—ã–π —Ñ–æ—Ä–º–∞—Ç - –æ–±—ä–µ–∫—Ç
        elif isinstance(result, dict):
            return result.get('status', 'unknown')
    elif response.status_code == 404:
        # –ï—Å–ª–∏ –∏–Ω–¥–µ–∫—Å–∞ –Ω–µ—Ç, –Ω—É–∂–Ω–æ –µ–≥–æ —Å–æ–∑–¥–∞—Ç—å
        return 'not_found'
    
    return 'error'

def main():
    print("üöÄ –ü–æ–ª–Ω–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ ElevenLabs Knowledge Base")
    print("=" * 60)
    
    # 1. –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
    print("\nüìö –ü–æ–ª—É—á–µ–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∏–∑ Knowledge Base...")
    kb_url = f"{base_url}/convai/knowledge-base"
    
    all_documents = []
    next_cursor = None
    
    while True:
        params = {}
        if next_cursor:
            params['cursor'] = next_cursor
        
        response = requests.get(kb_url, headers=headers, params=params)
        
        if response.status_code == 200:
            data = response.json()
            documents = data.get('documents', [])
            all_documents.extend(documents)
            
            if not data.get('has_more'):
                break
            next_cursor = data.get('next_cursor')
        else:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {response.status_code}")
            break
    
    print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(all_documents)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
    
    # 2. –§–∏–ª—å—Ç—Ä—É–µ–º –Ω–∞—à–∏ –¥–æ–∫—É–º–µ–Ω—Ç—ã MM-RAG
    mmrag_docs = []
    
    for doc in all_documents:
        doc_name = doc.get('name', '')
        doc_id = doc.get('id', '')
        
        if ('MM-RAG' in doc_name or 
            '–ö–≤–∞—Ä—Ç–∞–ª' in doc_name or 
            'Test Document' in doc_name):
            mmrag_docs.append({
                'id': doc_id,
                'name': doc_name
            })
    
    print(f"\nüìä –ù–∞–π–¥–µ–Ω–æ {len(mmrag_docs)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ MM-RAG")
    
    if not mmrag_docs:
        print("‚ùå –î–æ–∫—É–º–µ–Ω—Ç—ã MM-RAG –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
        return
    
    # 3. –ó–∞–ø—É—Å–∫–∞–µ–º –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—é RAG –¥–ª—è –≤—Å–µ—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
    print("\nüîß –ó–∞–ø—É—Å–∫ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ RAG...")
    
    indexed_docs = []
    
    for doc in mmrag_docs[:10]:  # –ò–Ω–¥–µ–∫—Å–∏—Ä—É–µ–º –ø–µ—Ä–≤—ã–µ 10 –¥–ª—è —Ç–µ—Å—Ç–∞
        success = compute_rag_index(doc['id'], doc['name'])
        if success:
            indexed_docs.append(doc)
        time.sleep(0.5)  # –ù–µ–±–æ–ª—å—à–∞—è –ø–∞—É–∑–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
    
    print(f"\n‚úÖ –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –∑–∞–ø—É—â–µ–Ω–∞ –¥–ª—è {len(indexed_docs)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
    
    # 4. –ñ–¥–µ–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏
    print("\n‚è≥ –û–∂–∏–¥–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ (–¥–æ 60 —Å–µ–∫—É–Ω–¥)...")
    
    max_wait = 60  # –ú–∞–∫—Å–∏–º—É–º 60 —Å–µ–∫—É–Ω–¥
    start_time = time.time()
    check_count = 0
    
    while time.time() - start_time < max_wait:
        all_indexed = True
        pending = []
        statuses = {}
        
        for doc in indexed_docs:
            status = check_rag_status(doc['id'])
            statuses[doc['name']] = status
            if status not in ['indexed', 'succeeded', 'created', 'indexing']:
                all_indexed = False
                pending.append(doc['name'])
        
        check_count += 1
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç–∞—Ç—É—Å—ã –ø–µ—Ä–≤—ã–π —Ä–∞–∑ –∏ –∫–∞–∂–¥—ã–µ 3 –ø—Ä–æ–≤–µ—Ä–∫–∏
        if check_count == 1 or check_count % 3 == 0:
            print(f"\n   –°—Ç–∞—Ç—É—Å –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ (–ø—Ä–æ–≤–µ—Ä–∫–∞ {check_count}):")
            for name, status in list(statuses.items())[:5]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 5
                print(f"      {name}: {status}")
        
        if all_indexed or not pending:
            print("‚úÖ –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –∏–ª–∏ –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ!")
            break
        else:
            print(f"   –û–∂–∏–¥–∞–Ω–∏–µ: {len(pending)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –Ω–µ –∏–Ω–¥–µ–∫—Å–∏—Ä—É—é—Ç—Å—è...")
            time.sleep(5)
    
    # 5. –§–æ—Ä–º–∏—Ä—É–µ–º —Å–ø–∏—Å–æ–∫ –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –≤ –∞–≥–µ–Ω—Ç–∞
    print("\nüìù –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è –∞–≥–µ–Ω—Ç–∞...")
    
    kb_entries = []
    for doc in indexed_docs:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —Å—Ç–∞—Ç—É—Å
        status = check_rag_status(doc['id'])
        
        if status in ['indexed', 'succeeded']:
            kb_entry = {
                "id": doc['id'],
                "name": doc['name'].replace(' ', '-').replace('–ö–≤–∞—Ä—Ç–∞–ª-', ''),
                "type": "text",
                "usage_mode": "auto"
            }
            kb_entries.append(kb_entry)
            print(f"   ‚úÖ {doc['name']}: –≥–æ—Ç–æ–≤ –∫ –¥–æ–±–∞–≤–ª–µ–Ω–∏—é")
        else:
            print(f"   ‚ö†Ô∏è {doc['name']}: –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è –Ω–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ ({status})")
    
    if not kb_entries:
        print("\n‚ùå –ù–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≥–æ—Ç–æ–≤—ã—Ö –∫ –¥–æ–±–∞–≤–ª–µ–Ω–∏—é")
        return
    
    # 6. –û–±–Ω–æ–≤–ª—è–µ–º –∞–≥–µ–Ω—Ç–∞
    print(f"\nü§ñ –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∞–≥–µ–Ω—Ç–∞ —Å {len(kb_entries)} –¥–æ–∫—É–º–µ–Ω—Ç–∞–º–∏...")
    
    # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—É—â—É—é –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
    agent_url = f"{base_url}/convai/agents/{agent_id}"
    response = requests.get(agent_url, headers=headers)
    
    if response.status_code != 200:
        print(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –∞–≥–µ–Ω—Ç–∞: {response.status_code}")
        return
    
    agent_data = response.json()
    current_kb = agent_data.get('conversation_config', {}).get('agent', {}).get('prompt', {}).get('knowledge_base', [])
    
    print(f"   –¢–µ–∫—É—â–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {len(current_kb)}")
    
    # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –∏ –Ω–æ–≤—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã
    existing_ids = {doc['id'] for doc in current_kb}
    
    for new_doc in kb_entries:
        if new_doc['id'] not in existing_ids:
            current_kb.append(new_doc)
    
    # –û–±–Ω–æ–≤–ª—è–µ–º –∞–≥–µ–Ω—Ç–∞
    update_data = {
        "conversation_config": {
            "agent": {
                "prompt": {
                    "knowledge_base": current_kb
                }
            }
        }
    }
    
    response = requests.patch(agent_url, headers=headers, json=update_data)
    
    if response.status_code == 200:
        print(f"‚úÖ –ê–≥–µ–Ω—Ç –æ–±–Ω–æ–≤–ª–µ–Ω! –í—Å–µ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {len(current_kb)}")
    else:
        print(f"‚ùå –û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è: {response.status_code}")
        error_detail = response.json().get('detail', {})
        if 'rag_index_not_ready' in str(error_detail):
            print("   –ù–µ–∫–æ—Ç–æ—Ä—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –µ—â–µ –Ω–µ –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω—ã")
            print("   –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –∑–∞–ø—É—Å—Ç–∏—Ç—å —Å–∫—Ä–∏–ø—Ç –ø–æ–∑–∂–µ")
        else:
            print(f"   –î–µ—Ç–∞–ª–∏: {response.text[:500]}")
    
    print("\n" + "=" * 60)
    print("‚ú® –ü—Ä–æ—Ü–µ—Å—Å –∑–∞–≤–µ—Ä—à–µ–Ω")
    print("\n–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:")
    print("1. –ï—Å–ª–∏ –Ω–µ –≤—Å–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –¥–æ–±–∞–≤–ª–µ–Ω—ã, –ø–æ–¥–æ–∂–¥–∏—Ç–µ 1-2 –º–∏–Ω—É—Ç—ã")
    print("2. –ó–∞–ø—É—Å—Ç–∏—Ç–µ —Å–∫—Ä–∏–ø—Ç –ø–æ–≤—Ç–æ—Ä–Ω–æ –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –æ—Å—Ç–∞–≤—à–∏—Ö—Å—è")
    print("3. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∞–≥–µ–Ω—Ç–∞ —á–µ—Ä–µ–∑ –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å ElevenLabs")


if __name__ == "__main__":
    main()