#!/usr/bin/env python3
"""
üßπ –°–∫—Ä–∏–ø—Ç –æ—á–∏—Å—Ç–∫–∏ ElevenLabs Knowledge Base –æ—Ç –¥—É–±–ª–∏–∫–∞—Ç–æ–≤

–£–¥–∞–ª—è–µ—Ç –≤—Å–µ —Å—Ç–∞—Ä—ã–µ –≤–µ—Ä—Å–∏–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤, –æ—Å—Ç–∞–≤–ª—è—è —Ç–æ–ª—å–∫–æ —Å–∞–º—É—é –Ω–æ–≤—É—é
–≤–µ—Ä—Å–∏—é –∫–∞–∂–¥–æ–≥–æ –∫–≤–∞—Ä—Ç–∞–ª–∞.

–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:
    python cleanup_elevenlabs_kb.py --dry-run   # –ü–æ–∫–∞–∑–∞—Ç—å —á—Ç–æ –±—É–¥–µ—Ç —É–¥–∞–ª–µ–Ω–æ
    python cleanup_elevenlabs_kb.py --execute   # –í—ã–ø–æ–ª–Ω–∏—Ç—å —É–¥–∞–ª–µ–Ω–∏–µ
"""

import os
import sys
import json
import time
import argparse
import requests
from datetime import datetime
from collections import defaultdict
from dotenv import load_dotenv

load_dotenv()

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
API_KEY = os.environ.get('ELEVENLABS_API_KEY')
AGENT_ID = os.environ.get('ELEVENLABS_AGENT_ID')
BASE_URL = "https://api.elevenlabs.io/v1"

def log(msg):
    """–í—ã–≤–æ–¥ —Å –≤—Ä–µ–º–µ–Ω–Ω–æ–π –º–µ—Ç–∫–æ–π"""
    timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    print(f"[{timestamp}] {msg}")
    sys.stdout.flush()

def get_all_kb_documents():
    """–ü–æ–ª—É—á–∏—Ç—å –≤—Å–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –∏–∑ Knowledge Base"""
    all_docs = []
    page = 0
    max_pages = 200  # –î–æ 20,000 –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
    
    log("üì• –ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∏–∑ KB...")
    
    while page < max_pages:
        url = f"{BASE_URL}/convai/knowledge-base?page_size=100&page={page}"
        
        try:
            response = requests.get(
                url, 
                headers={"xi-api-key": API_KEY}, 
                timeout=60
            )
            
            if response.status_code != 200:
                log(f"‚ùå HTTP {response.status_code} –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ {page}")
                break
            
            data = response.json()
            docs = data.get('documents', data.get('knowledge_bases', []))
            
            if not docs:
                log(f"‚úÖ –í—Å–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –ø–æ–ª—É—á–µ–Ω—ã (—Å—Ç—Ä–∞–Ω–∏—Ü–∞ {page})")
                break
            
            all_docs.extend(docs)
            
            if page % 10 == 0:
                log(f"   üìÑ –°—Ç—Ä–∞–Ω–∏—Ü–∞ {page}: –≤—Å–µ–≥–æ {len(all_docs)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
            
            has_more = data.get('has_more', False)
            if not has_more:
                break
            
            page += 1
            time.sleep(0.3)  # Rate limiting
            
        except Exception as e:
            log(f"‚ùå –û—à–∏–±–∫–∞ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ {page}: {e}")
            break
    
    log(f"üìä –í—Å–µ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ KB: {len(all_docs)}")
    return all_docs

def analyze_documents(all_docs):
    """–ê–Ω–∞–ª–∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ - –Ω–∞–π—Ç–∏ –¥—É–±–ª–∏–∫–∞—Ç—ã"""
    grouped = defaultdict(list)
    
    # –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –ø–æ –±–∞–∑–æ–≤–æ–º—É –∏–º–µ–Ω–∏
    for doc in all_docs:
        name = doc.get('name', '')
        
        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å–∏—Å—Ç–µ–º–Ω—ã–µ
        if any(x in name.lower() for x in ['system', 'prompt', 'elevenlabs_rag']):
            continue
        
        # –ë–∞–∑–æ–≤–æ–µ –∏–º—è (–±–µ–∑ –¥–∞—Ç –∏ –≤–µ—Ä—Å–∏–π)
        import re
        base_name = re.sub(r'-v\d+|-\d{4}-\d{2}-\d{2}', '', name)
        base_name = re.sub(r'\.(txt|md|html)$', '', base_name)
        
        # –ü–æ–ª—É—á–∞–µ–º –¥–∞—Ç—É —Å–æ–∑–¥–∞–Ω–∏—è
        metadata = doc.get('metadata', {})
        created = metadata.get('created_at_unix_secs', 0)
        
        grouped[base_name].append({
            'id': doc.get('id'),
            'name': name,
            'created': created,
            'created_str': datetime.fromtimestamp(created).strftime('%Y-%m-%d %H:%M:%S') if created else 'unknown'
        })
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —á—Ç–æ –æ—Å—Ç–∞–≤–∏—Ç—å –∏ —á—Ç–æ —É–¥–∞–ª–∏—Ç—å
    to_keep = []
    to_delete = []
    
    for base_name, versions in grouped.items():
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –¥–∞—Ç–µ (–Ω–æ–≤—ã–µ –ø–µ—Ä–≤—ã–µ)
        versions_sorted = sorted(versions, key=lambda x: x['created'], reverse=True)
        
        # –ü–µ—Ä–≤—ã–π (—Å–∞–º—ã–π –Ω–æ–≤—ã–π) - –æ—Å—Ç–∞–≤–ª—è–µ–º
        if versions_sorted:
            to_keep.append(versions_sorted[0])
        
        # –û—Å—Ç–∞–ª—å–Ω—ã–µ - —É–¥–∞–ª—è–µ–º
        for v in versions_sorted[1:]:
            to_delete.append(v)
    
    return to_keep, to_delete, grouped

def delete_document(doc_id):
    """–£–¥–∞–ª–∏—Ç—å –æ–¥–∏–Ω –¥–æ–∫—É–º–µ–Ω—Ç"""
    url = f"{BASE_URL}/convai/knowledge-base/{doc_id}"
    
    try:
        response = requests.delete(
            url,
            headers={"xi-api-key": API_KEY},
            timeout=30
        )
        if response.status_code == 400:
            # –î–æ–∫—É–º–µ–Ω—Ç –ø—Ä–∏–≤—è–∑–∞–Ω –∫ –∞–≥–µ–Ω—Ç—É
            return False, "dependent"
        return response.status_code in [200, 204], "ok"
    except Exception as e:
        log(f"‚ùå –û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è {doc_id}: {e}")
        return False, "error"

def update_agent_kb(keep_ids: list) -> bool:
    """–û–±–Ω–æ–≤–∏—Ç—å –∞–≥–µ–Ω—Ç–∞ - —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å —Ç–æ–ª—å–∫–æ —É–∫–∞–∑–∞–Ω–Ω—ã–µ ID –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤"""
    if not AGENT_ID:
        log("‚ùå ELEVENLABS_AGENT_ID –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω!")
        return False
    
    agent_url = f"{BASE_URL}/convai/agents/{AGENT_ID}"
    
    log(f"ü§ñ –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∞–≥–µ–Ω—Ç–∞ {AGENT_ID}...")
    log(f"   –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º {len(keep_ids)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
    
    # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—É—â—É—é –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
    try:
        resp = requests.get(agent_url, headers={"xi-api-key": API_KEY}, timeout=60)
        if resp.status_code != 200:
            log(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∞–≥–µ–Ω—Ç–∞: {resp.status_code}")
            return False
        
        agent_data = resp.json()
        current_kb = agent_data.get('conversation_config', {}).get('knowledge_base', {})
        current_ids = current_kb.get('ids', [])
        log(f"   –¢–µ–∫—É—â–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ –∞–≥–µ–Ω—Ç–µ: {len(current_ids)}")
        
    except Exception as e:
        log(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∞–≥–µ–Ω—Ç–∞: {e}")
        return False
    
    # –û–±–Ω–æ–≤–ª—è–µ–º –∞–≥–µ–Ω—Ç–∞
    update_data = {
        'conversation_config': {
            'knowledge_base': {
                'type': 'knowledge_base',
                'ids': keep_ids[:50]  # –õ–∏–º–∏—Ç 50
            }
        }
    }
    
    try:
        resp = requests.patch(
            agent_url,
            headers={"xi-api-key": API_KEY, "Content-Type": "application/json"},
            json=update_data,
            timeout=120
        )
        
        if resp.status_code == 200:
            log(f"‚úÖ –ê–≥–µ–Ω—Ç –æ–±–Ω–æ–≤–ª–µ–Ω! –¢–µ–ø–µ—Ä—å {len(keep_ids[:50])} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
            return True
        else:
            log(f"‚ùå –û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –∞–≥–µ–Ω—Ç–∞: {resp.status_code}")
            log(f"   –û—Ç–≤–µ—Ç: {resp.text[:300]}")
            return False
            
    except Exception as e:
        log(f"‚ùå –û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –∞–≥–µ–Ω—Ç–∞: {e}")
        return False

def main():
    parser = argparse.ArgumentParser(description='–û—á–∏—Å—Ç–∫–∞ ElevenLabs KB –æ—Ç –¥—É–±–ª–∏–∫–∞—Ç–æ–≤')
    parser.add_argument('--dry-run', action='store_true', help='–¢–æ–ª—å–∫–æ –ø–æ–∫–∞–∑–∞—Ç—å —á—Ç–æ –±—É–¥–µ—Ç —É–¥–∞–ª–µ–Ω–æ')
    parser.add_argument('--execute', action='store_true', help='–í—ã–ø–æ–ª–Ω–∏—Ç—å —É–¥–∞–ª–µ–Ω–∏–µ')
    parser.add_argument('--yes', '-y', action='store_true', help='–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ (–±–µ–∑ input)')
    parser.add_argument('--batch-size', type=int, default=50, help='–†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è')
    args = parser.parse_args()
    
    if not args.dry_run and not args.execute:
        print("–£–∫–∞–∂–∏—Ç–µ --dry-run –∏–ª–∏ --execute")
        print("  --dry-run  - –ø–æ–∫–∞–∑–∞—Ç—å —á—Ç–æ –±—É–¥–µ—Ç —É–¥–∞–ª–µ–Ω–æ")
        print("  --execute  - –≤—ã–ø–æ–ª–Ω–∏—Ç—å —É–¥–∞–ª–µ–Ω–∏–µ")
        sys.exit(1)
    
    if not API_KEY:
        log("‚ùå ELEVENLABS_API_KEY –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω!")
        sys.exit(1)
    
    if not AGENT_ID and args.execute:
        log("‚ùå ELEVENLABS_AGENT_ID –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω!")
        log("   –ù—É–∂–µ–Ω –¥–ª—è –æ—Ç–≤—è–∑–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –æ—Ç –∞–≥–µ–Ω—Ç–∞ –ø–µ—Ä–µ–¥ —É–¥–∞–ª–µ–Ω–∏–µ–º")
        sys.exit(1)
    
    log("üßπ –û—á–∏—Å—Ç–∫–∞ ElevenLabs Knowledge Base")
    log("=" * 60)
    
    # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã
    all_docs = get_all_kb_documents()
    
    if not all_docs:
        log("‚ÑπÔ∏è  –î–æ–∫—É–º–µ–Ω—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
        return
    
    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º
    to_keep, to_delete, grouped = analyze_documents(all_docs)
    
    log("")
    log("=" * 60)
    log("üìä –ê–ù–ê–õ–ò–ó:")
    log(f"   üìö –í—Å–µ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {len(all_docs)}")
    log(f"   ‚úÖ –û—Å—Ç–∞–≤–∏—Ç—å (—É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö): {len(to_keep)}")
    log(f"   üóëÔ∏è  –£–¥–∞–ª–∏—Ç—å (–¥—É–±–ª–∏–∫–∞—Ç–æ–≤): {len(to_delete)}")
    log("")
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –≥—Ä—É–ø–ø—ã —Å –¥—É–±–ª–∏–∫–∞—Ç–∞–º–∏
    log("üìã –ì—Ä—É–ø–ø—ã —Å –¥—É–±–ª–∏–∫–∞—Ç–∞–º–∏:")
    for base_name, versions in sorted(grouped.items()):
        if len(versions) > 1:
            log(f"   {base_name}: {len(versions)} –≤–µ—Ä—Å–∏–π")
            for i, v in enumerate(sorted(versions, key=lambda x: x['created'], reverse=True)[:3]):
                marker = "‚úÖ" if i == 0 else "üóëÔ∏è"
                log(f"      {marker} {v['name']} ({v['created_str']})")
            if len(versions) > 3:
                log(f"      ... –∏ –µ—â–µ {len(versions) - 3} –≤–µ—Ä—Å–∏–π")
    
    if args.dry_run:
        log("")
        log("=" * 60)
        log("üîç DRY RUN - —É–¥–∞–ª–µ–Ω–∏–µ –Ω–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–æ")
        log(f"   –î–ª—è —É–¥–∞–ª–µ–Ω–∏—è –∑–∞–ø—É—Å—Ç–∏—Ç–µ: python cleanup_elevenlabs_kb.py --execute")
        return
    
    # –í—ã–ø–æ–ª–Ω—è–µ–º —É–¥–∞–ª–µ–Ω–∏–µ
    if args.execute:
        log("")
        log("=" * 60)
        log(f"üóëÔ∏è  –ü–õ–ê–ù –û–ß–ò–°–¢–ö–ò:")
        log(f"   1. –û–±–Ω–æ–≤–∏—Ç—å –∞–≥–µ–Ω—Ç–∞ - –æ—Å—Ç–∞–≤–∏—Ç—å —Ç–æ–ª—å–∫–æ {len(to_keep)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
        log(f"   2. –£–¥–∞–ª–∏—Ç—å {len(to_delete)} –æ—Ç–≤—è–∑–∞–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
        log("")
        
        # –ü–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ
        if not args.yes:
            try:
                confirm = input(f"–í—ã —É–≤–µ—Ä–µ–Ω—ã? (yes/no): ")
                if confirm.strip().lower() != 'yes':
                    log("‚ùå –û—Ç–º–µ–Ω–µ–Ω–æ")
                    return
            except EOFError:
                log("‚ùå –û—Ç–º–µ–Ω–µ–Ω–æ (–Ω–µ—Ç –≤–≤–æ–¥–∞, –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ --yes –¥–ª—è –∞–≤—Ç–æ–ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è)")
                return
        else:
            log("‚úÖ –ê–≤—Ç–æ–ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ (--yes)")
        
        # –®–ê–ì 1: –û–±–Ω–æ–≤–ª—è–µ–º –∞–≥–µ–Ω—Ç–∞
        log("")
        log("=" * 60)
        log("üìå –®–ê–ì 1: –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∞–≥–µ–Ω—Ç–∞")
        log("=" * 60)
        
        keep_ids = [doc['id'] for doc in to_keep]
        log(f"   ID –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è: {len(keep_ids)}")
        for doc in to_keep:
            log(f"      ‚úÖ {doc['name']}")
        
        if not update_agent_kb(keep_ids):
            log("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±–Ω–æ–≤–∏—Ç—å –∞–≥–µ–Ω—Ç–∞!")
            log("   –£–¥–∞–ª–µ–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –æ—Ç–º–µ–Ω–µ–Ω–æ (–æ–Ω–∏ –≤—Å—ë –µ—â—ë –ø—Ä–∏–≤—è–∑–∞–Ω—ã)")
            return
        
        log("")
        log("‚è≥ –ñ–¥—ë–º 5 —Å–µ–∫—É–Ω–¥ –¥–ª—è –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è –∏–∑–º–µ–Ω–µ–Ω–∏–π...")
        time.sleep(5)
        
        # –®–ê–ì 2: –£–¥–∞–ª—è–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã
        log("")
        log("=" * 60)
        log(f"üóëÔ∏è  –®–ê–ì 2: –£–¥–∞–ª–µ–Ω–∏–µ {len(to_delete)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
        log("=" * 60)
        
        deleted = 0
        failed = 0
        dependent = 0
        
        start_time = time.time()
        
        for i, doc in enumerate(to_delete, 1):
            success, status = delete_document(doc['id'])
            
            if success:
                deleted += 1
            elif status == "dependent":
                dependent += 1
            else:
                failed += 1
            
            # –ü—Ä–æ–≥—Ä–µ—Å—Å –∫–∞–∂–¥—ã–µ 100 –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
            if i % 100 == 0:
                elapsed = time.time() - start_time
                rate = i / elapsed if elapsed > 0 else 0
                remaining = (len(to_delete) - i) / rate if rate > 0 else 0
                log(f"   –ü—Ä–æ–≥—Ä–µ—Å—Å: {i}/{len(to_delete)} ({deleted} ‚úÖ, {dependent} üîó, {failed} ‚ùå) | {rate:.1f} –¥–æ–∫/—Å–µ–∫ | ~{remaining/60:.0f} –º–∏–Ω")
                time.sleep(0.5)
            else:
                time.sleep(0.1)
        
        log("")
        log("=" * 60)
        log("‚úÖ –ì–û–¢–û–í–û!")
        log(f"   –£–¥–∞–ª–µ–Ω–æ: {deleted}")
        log(f"   –í—Å—ë –µ—â—ë –ø—Ä–∏–≤—è–∑–∞–Ω—ã: {dependent}")
        log(f"   –û—à–∏–±–æ–∫: {failed}")
        log(f"   –û—Å—Ç–∞–ª–æ—Å—å –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: ~{len(to_keep)}")
        
        if dependent > 0:
            log("")
            log(f"‚ö†Ô∏è  {dependent} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤—Å—ë –µ—â—ë –ø—Ä–∏–≤—è–∑–∞–Ω—ã –∫ –∞–≥–µ–Ω—Ç—É")
            log("   –ó–∞–ø—É—Å—Ç–∏—Ç–µ —Å–∫—Ä–∏–ø—Ç –µ—â—ë —Ä–∞–∑ –¥–ª—è –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –ø–æ–ø—ã—Ç–∫–∏")

if __name__ == "__main__":
    main()

